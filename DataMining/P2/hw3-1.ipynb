{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS 484 :: Data Mining :: George Mason University :: Spring 2025\n",
    "\n",
    "\n",
    "# Homework 3: Clustering\n",
    "\n",
    "- **100 points [6% of your final grade]**\n",
    "- **Due Wednesday, April 09 by 11:59pm**\n",
    "\n",
    "- *Goals of this homework:* (1) implement your K-means model; (2) Apply PCA to K-Means.\n",
    "\n",
    "- *Submission instructions:* for this homework, you only need to submit to Blackboard. Please name your submission **FirstName_Lastname_hw3.ipynb**, so for example, my submission would be something like **Ziwei_Zhu_hw3.ipynb**. Your notebook should be fully executed so that we can see all outputs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: K-Means (70 points)\n",
    "\n",
    "In this part, you will implement your own K-means algorithm to conduct clustering on handwritten digit images. In this homework, we will still use the handwritten digit image dataset we have already used in previous homework. However, since clustering is unsupervised learning, which means we do not use the label information anymore. So, here, we will only use the testing data stored in the \"test.txt\" file.\n",
    "\n",
    "First, let's load the data by excuting the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array of testing feature matrix: shape (10000, 784)\n",
      "array of testing label matrix: shape (10000,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "test = np.loadtxt(\"test.txt\", delimiter=',')\n",
    "test_features = test[:, 1:]\n",
    "test_labels = test[:, 0]\n",
    "print('array of testing feature matrix: shape ' + str(np.shape(test_features)))\n",
    "print('array of testing label matrix: shape ' + str(np.shape(test_labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, it's time for you to implement your own K-means algorithm. First, please write your code to build your K-means model using the image data with **K = 10**, and **Euclidean distance**.\n",
    "\n",
    "**Note: You should implement the algorithm by yourself. You are NOT allowed to use Machine Learning libraries like Sklearn**\n",
    "\n",
    "**Note: you need to decide when to stop the iteration.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-means converged in 57 iterations.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "def k_means_clustering(test_features, k=10):\n",
    "    # Initialize centroids by randomly selecting k points\n",
    "    kcentroids = [test_features[np.random.randint(0, len(test_features))] for _ in range(k)]\n",
    "    kcentroids = np.array(kcentroids)\n",
    "\n",
    "    flag = False\n",
    "    iteration = 0\n",
    "\n",
    "    while not flag:\n",
    "        # Reset clusters\n",
    "        clusters = [[] for _ in range(k)]\n",
    "\n",
    "        # Assign points to the nearest centroid\n",
    "        for i, row in enumerate(test_features):\n",
    "            closest_dist = sys.float_info.max\n",
    "            closest_idx = 0\n",
    "            for idx, centroid in enumerate(kcentroids):\n",
    "                dist = np.linalg.norm(row - centroid)\n",
    "                if dist < closest_dist:\n",
    "                    closest_dist = dist\n",
    "                    closest_idx = idx\n",
    "            clusters[closest_idx].append(i)\n",
    "\n",
    "        # Update centroids\n",
    "        new_centroids = np.zeros_like(kcentroids)\n",
    "        for idx, cluster in enumerate(clusters):\n",
    "            if len(cluster) > 0:\n",
    "                points = test_features[cluster]  # Fetch by index\n",
    "                new_centroids[idx] = np.mean(points, axis=0)\n",
    "            else:\n",
    "                # Reinitialize empty cluster\n",
    "                new_centroids[idx] = test_features[np.random.randint(0, len(test_features))]\n",
    "\n",
    "        # Check convergence\n",
    "        if np.allclose(kcentroids, new_centroids):\n",
    "            flag = True\n",
    "        else:\n",
    "            kcentroids = new_centroids\n",
    "\n",
    "        iteration += 1\n",
    "\n",
    "    return kcentroids, clusters, iteration\n",
    "\n",
    "# Example usage\n",
    "kcentroids, clusters, iteration = k_means_clustering(test_features, k=10)\n",
    "print(f\"K-means converged in {iteration} iterations.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you need to calculate and print the **square root** of **S**um of **S**quared **E**rror (SSE) of each cluster generated by your K-means algorithm. Then, print out the averaged square root of SSE over all clusters.\n",
    "\n",
    "**Note: The value of \"square root of SSE\" can diverge significantly. The expected value range is 10000~100000.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0 - sqrt(SSE): 35172.3752\n",
      "Cluster 1 - sqrt(SSE): 52431.6118\n",
      "Cluster 2 - sqrt(SSE): 62310.8753\n",
      "Cluster 3 - sqrt(SSE): 35564.7404\n",
      "Cluster 4 - sqrt(SSE): 49338.2069\n",
      "Cluster 5 - sqrt(SSE): 49138.4388\n",
      "Cluster 6 - sqrt(SSE): 50235.8613\n",
      "Cluster 7 - sqrt(SSE): 57684.1139\n",
      "Cluster 8 - sqrt(SSE): 44813.5720\n",
      "Cluster 9 - sqrt(SSE): 59007.6027\n",
      "\n",
      "Average sqrt(SSE) across all clusters: 49569.7398\n"
     ]
    }
   ],
   "source": [
    "# Write your code here\n",
    "def calculate_sqrt_sse(test_features, clusters, kcentroids):\n",
    "    sqrt_sse_list = []\n",
    "\n",
    "    for idx, cluster_indices in enumerate(clusters):\n",
    "        if len(cluster_indices) > 0:\n",
    "            points = test_features[cluster_indices]  # Fetch rows by index\n",
    "            diffs = points - kcentroids[idx]         # Now shapes match!\n",
    "            sse = np.sum(np.square(diffs))\n",
    "            sqrt_sse = np.sqrt(sse)\n",
    "            sqrt_sse_list.append(sqrt_sse)\n",
    "            print(f\"Cluster {idx} - sqrt(SSE): {sqrt_sse:.4f}\")\n",
    "        else:\n",
    "            print(f\"Cluster {idx} is empty.\")\n",
    "\n",
    "    # Average of the square roots of SSEs\n",
    "    if sqrt_sse_list:\n",
    "        avg_sqrt_sse = np.mean(sqrt_sse_list)\n",
    "        print(f\"\\nAverage sqrt(SSE) across all clusters: {avg_sqrt_sse:.4f}\")\n",
    "    else:\n",
    "        print(\"No non-empty clusters to calculate SSE.\")\n",
    "    \n",
    "    return sqrt_sse_list  # Return list if needed for further use\n",
    "\n",
    "# Example usage\n",
    "sqrt_sse_list = calculate_sqrt_sse(test_features, clusters, kcentroids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, please have a look on https://scikit-learn.org/stable/modules/generated/sklearn.metrics.homogeneity_completeness_v_measure.html#sklearn.metrics.homogeneity_completeness_v_measure, and use this function to print out the homogeneity, completeness, and v-measure of your K-means model.\n",
    "\n",
    "**Note: The values of homogeneity, completeness, and v-measure are expected to be >0.48**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Homogeneity: 0.4988\n",
      "Completeness: 0.5022\n",
      "V-measure: 0.5005\n"
     ]
    }
   ],
   "source": [
    "# Write your code here\n",
    "from sklearn.metrics import homogeneity_completeness_v_measure\n",
    "\n",
    "def evaluate_clustering_performance1(test_labels, clusters):\n",
    "    # Initialize predicted_labels as an array of zeros with the same length as test_labels\n",
    "    predicted_labels = np.empty(len(test_labels), dtype=int)\n",
    "\n",
    "    # Assign the predicted labels based on cluster indices\n",
    "    for cluster_idx, point_indices in enumerate(clusters):\n",
    "        for i in point_indices:\n",
    "            predicted_labels[i] = cluster_idx\n",
    "\n",
    "    return predicted_labels\n",
    "# Example usage\n",
    "pred = evaluate_clustering_performance1(test_labels, clusters)\n",
    "h, c, v = homogeneity_completeness_v_measure(test_labels, pred)\n",
    "\n",
    "# Print results\n",
    "print(f\"\\nHomogeneity: {h:.4f}\")\n",
    "print(f\"Completeness: {c:.4f}\")\n",
    "print(f\"V-measure: {v:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Dimension Reduction by PCA (30 points)\n",
    "\n",
    "Last, in this part, please use PCA to reduce the feature dimension here. And then, apply your K-Means code to the reduced data and report homogeneity, completeness, and v-measure.\n",
    "\n",
    "**Note: You need to consider the reduced dimension m of PCA as a hyper-parameter to tune. That is, you need to try different m and measure the corresponding clustering performance. At the end, you need to report the best m and clustering performance.**\n",
    "\n",
    "**Note: Everything else is the same as Part1, i.e., K=10, and you need to use Euclidean distance.**\n",
    "\n",
    "**Note: You can reuse your own code of PCA from your HW1, or you can directly use the PCA model from sklearn -- https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating for 50 PCA components...\n"
     ]
    }
   ],
   "source": [
    "# Write your code here\n",
    "from sklearn.decomposition import PCA\n",
    "def evaluate_clustering_performance2(test_features, k,pcaDim):\n",
    "    # Try different dimensions for PCA\n",
    "\n",
    "    print(f\"\\nEvaluating for {pcaDim} PCA components...\")\n",
    "    \n",
    "    # Apply PCA to reduce the feature space to m dimensions\n",
    "    pca = PCA(pcaDim)\n",
    "    reduced_features = pca.fit_transform(test_features)\n",
    "    \n",
    "    # Apply custom K-means clustering on the reduced data\n",
    "    centroids, clusters, iter = k_means_clustering(reduced_features, k)\n",
    "    return clusters\n",
    "\n",
    "# Example usage\n",
    "clusters = evaluate_clustering_performance2(test_features,10,50)\n",
    "pred = evaluate_clustering_performance1(test_labels, clusters)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cell, use sklearn.metrics.homogeneity_completeness_v_measure() to print out the homogeneity, completeness, and v-measure of your K-means++ model.\n",
    "\n",
    "**Note: The values of homogeneity, completeness, and v-measure are expected to be >0.48**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Homogeneity: 0.4912\n",
      "Best Completeness: 0.5040\n",
      "Best V-measure: 0.4976\n"
     ]
    }
   ],
   "source": [
    "# Write your code here\n",
    "h, c, v = homogeneity_completeness_v_measure(test_labels, pred)\n",
    "print(f\"Best Homogeneity: {h:.4f}\")\n",
    "print(f\"Best Completeness: {c:.4f}\")\n",
    "print(f\"Best V-measure: {v:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
